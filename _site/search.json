[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I am a Data Scientist who has worked in a variety of roles across the sports betting, voluntary and e-commerce sectors. This is a technical blog writing about all things data science (currently they’re mostly about cricket though), I also blog about any random thoughts that come to my head on medium, and I have a couple of old cricket articles on wordpress. To find out more about me, check out my first blog post or feel free to get in touch!\n\nContact me\nbfern1994@gmail.com"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "bfern",
    "section": "",
    "text": "IPL Final Contributions Scorecard\n\n\n\n\n\n\ncricket\n\n\ndata science\n\n\nr\n\n\nvisualisation\n\n\n\n\n\n\n\n\n\nJun 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nIntroducing Contribution Score\n\n\n\n\n\n\ncricket\n\n\ndata science\n\n\nr\n\n\nvisualisation\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nEffective Ways of Working in a Remote Data Science Team\n\n\n\n\n\n\ndata science\n\n\n\n\n\n\n\n\n\nMay 16, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nIPL 2022 Pre Auction Indian Player Analysis\n\n\n\n\n\n\ncricket\n\n\ndata science\n\n\nr\n\n\n\n\n\n\n\n\n\nFeb 11, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nStructuring the English County Season\n\n\n\n\n\n\ncricket\n\n\n\n\n\n\n\n\n\nDec 31, 2021\n\n\n\n\n\n\n\n\n\n\n\n\nA Statistical Analysis of Jimmy Andersons Test Batting Career in R\n\n\n\n\n\n\ncricket\n\n\ndata science\n\n\nr\n\n\n\n\n\n\n\n\n\nNov 18, 2021\n\n\n\n\n\n\n\n\n\n\n\n\nA Shiny Dashboard for Cricket Scoring\n\n\n\n\n\n\ncricket\n\n\ndata science\n\n\nr\n\n\nvisualisation\n\n\n\n\n\n\n\n\n\nAug 3, 2021\n\n\n\n\n\n\n\n\n\n\n\n\nMy First Blog Post\n\n\n\n\n\n\ngeneral\n\n\n\n\n\n\n\n\n\nJul 30, 2021\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2021-08-03-a-shiny-dashboard-for-cricket-scoring.md/index.html",
    "href": "posts/2021-08-03-a-shiny-dashboard-for-cricket-scoring.md/index.html",
    "title": "A Shiny Dashboard for Cricket Scoring",
    "section": "",
    "text": "As I said in my previous blog post, I am a cricket fanatic. I’ve always wanted to find a resource where I could see the scorecard of professional cricket matches - as an example see the scorecard here. However there did not appear to be anywhere that did this, so I decided to create a web application myself to do this. As a strong R programmer, Shiny seemed like a great tool that would allow me to do this. The app can be found here."
  },
  {
    "objectID": "posts/2021-08-03-a-shiny-dashboard-for-cricket-scoring.md/index.html#how-to-use",
    "href": "posts/2021-08-03-a-shiny-dashboard-for-cricket-scoring.md/index.html#how-to-use",
    "title": "A Shiny Dashboard for Cricket Scoring",
    "section": "How to use",
    "text": "How to use\nThe Matches tab gives you a list of Twenty20 matches for the specified date range, competitions and even a certain team if you decide to. For the match that you would like to view, then click on the “Go to Scorecard” button and the scorecard will open in the Scorecard tab. You can also toggle which innings you would like to see. To change the match, go back to the Matches tab and click on a new game.\nPlease be aware that if you have not yet selected a match by clicking the “Go to Scorecard” button in the Matches tab, then the Scorecard tab will be full of errors."
  },
  {
    "objectID": "posts/2021-08-03-a-shiny-dashboard-for-cricket-scoring.md/index.html#future-to-dos",
    "href": "posts/2021-08-03-a-shiny-dashboard-for-cricket-scoring.md/index.html#future-to-dos",
    "title": "A Shiny Dashboard for Cricket Scoring",
    "section": "Future to dos",
    "text": "Future to dos\n\nMore formats other than just Twenty20.\nUse different colours for different bowlers, so you can see how each batsman fared against the different bowlers.\nAdd the ability to click on a player and see an analytical overview of their stats broken down by year, competiton, etc."
  },
  {
    "objectID": "posts/2021-07-30-my-first-blog-post/index.html",
    "href": "posts/2021-07-30-my-first-blog-post/index.html",
    "title": "My First Blog Post",
    "section": "",
    "text": "I could probably do with adding something to this website, so let’s start by talking a little bit about myself.\nMy name’s Brad, I’m in my mid to late 20s and currently living in London. I think I’ve decided to write this because I’m not too sure what I’m doing with my life. As I expect many other people can relate to, the pandemic has given us more time to think and decide what we really want to get out of life. Maybe putting my thoughts down on paper will help.\nIn this blog I plan to write about a variety of topics, but in particular I want to write about things that interest me. And even better if I can combine two or more of such things! These things are:\nMaths. From a young age, I have loved numbers. When I was 8 or 9 years old, I would get home from school and watch countdown, waiting patiently for each numbers game just before the advert break. This was in the pre sky+ days, so I was under strict time pressure to find an answer (although my Dad is a big fan of the invention, I once found him sitting in front of a paused numbers game with “-26 mins” displayed). Sadly my mental arithmetic is not what it used to be, however my hunger for mathematics has not disappeared.\nSport, especially cricket. I am a cricket fanatic, I’ve spent way too many hours of my waking hours (also a lot where I should have been sleeping too) watching cricket, and I have sent down countless leg spinners to my brother in the local field (including a few ball of the century contenders). I also enjoy football, and just love sport in general.\nData Science. I kinda just fell into this field - I saw a role advertised that was for maths and sport, and five years later I’m still working in the same sector. Little did I know back then that this was data science, what data science was, or that data science is the sexiest job of the 21st century (https://hbr.org/2012/10/data-scientist-the-sexiest-job-of-the-21st-century). Data can improve our understanding of the world, which is pretty cool.\nProblem solving, logical thinking, etc. I’m nerdy what can I say.\nMaking society a better place. We all know there’s a lot wrong with it. And when you spend time thinking about it even more, you realise there’s even more wrong with it. Some particular issues that I care about are tech addition, loneliness in an increasingly global world, and understanding what truly makes people happy.\nIf anybody does stumble across this and for some mysterious reason fancies getting in contact with me then my email is bfern1994@gmail.com."
  },
  {
    "objectID": "posts/2021-11-18-a-statistical-analysis-of-jimmy-andersons-test-career-in-r/index.html",
    "href": "posts/2021-11-18-a-statistical-analysis-of-jimmy-andersons-test-career-in-r/index.html",
    "title": "A Statistical Analysis of Jimmy Andersons Test Batting Career in R",
    "section": "",
    "text": "library(dplyr)\nlibrary(ggplot2)\nlibrary(rstan)\nlibrary(lubridate)\n\noptions(mc.cores = parallel::detectCores())\nrstan_options(auto_write = TRUE)\n\nbatting &lt;- readRDS(\"data/batting.rds\")"
  },
  {
    "objectID": "posts/2021-11-18-a-statistical-analysis-of-jimmy-andersons-test-career-in-r/index.html#exponential-weighted-moving-average",
    "href": "posts/2021-11-18-a-statistical-analysis-of-jimmy-andersons-test-career-in-r/index.html#exponential-weighted-moving-average",
    "title": "A Statistical Analysis of Jimmy Andersons Test Batting Career in R",
    "section": "Exponential Weighted Moving Average",
    "text": "Exponential Weighted Moving Average\nThe first model that I will construct will be an exponential weighted moving mean. I will take each timestep as an individual innings, and optimize the weight such that the log likelihood is maximised. I do this in a slightly weird way where I recalculate the weighting parameter for each new observation in the test set - the reason I do this becomes clearer once I describe the state space model below.\n\nsource(\"src/exponential_weighted_moving_average.R\")\n\nwarm_up_cut_off_year &lt;- 2009\ntrain_cut_off_year &lt;- 2016\n\nwarm_up_cut_off &lt;- batting %&gt;%\n  filter(year(date) &lt;= warm_up_cut_off_year) %&gt;%\n  nrow\n\ntrain_cut_off &lt;- batting %&gt;%\n  filter(year(date) &lt;= train_cut_off_year) %&gt;%\n  nrow\n\nweights &lt;- numeric(nrow(batting))\nfor (i in (train_cut_off+1):nrow(batting)) {\n  train &lt;- batting %&gt;%\n    filter(innings_no &lt; i)\n  weights[i] &lt;- get_optimal_weight(\n    warm_up_cut_off,\n    train$innings_no,\n    train$score,\n    !train$dismissed\n  )\n}\n\nprint(paste0(\"The optimal weight is: \", weights[nrow(batting)]))\n\n[1] \"The optimal weight is: 0.0157578544617485\"\n\n\nWe can now use our calculated weights for each time point to calculate our predicted parameters for the test set, which we will then plot:\n\nparams_by_timestep &lt;- numeric(nrow(batting))\nfor (i in (train_cut_off+1):nrow(batting)) {\n  params_by_timestep[i] &lt;- get_params_by_timestep(\n    weights[i],\n    warm_up_cut_off = warm_up_cut_off,\n    timestep_vec = batting$innings_no,\n    score_vec = batting$score,\n    not_out_vec = !batting$dismissed\n  )[i]\n}\n\nweighted_moving_ave_preds_by_innings_df &lt;- tibble(\n  innings_no  = 1:max(batting$innings_no),\n  param = params_by_timestep\n) %&gt;%\n  filter(innings_no &gt; train_cut_off)\n\nweighted_moving_ave_preds_by_innings_df %&gt;%\n  ggplot(aes(x = innings_no, y = param)) +\n  geom_point() +\n  scale_x_continuous(name = \"Innings Number\") +\n  scale_y_continuous(name = \"Parameter\")\n\n\n\n\n\n\n\n\nI will now construct a model in the same way as above, but instead of taking each timestep as an individual innings, I will only take the timesteps as individual years.\n\nweights &lt;- numeric(max(year(batting$date)))\nfor (i in (train_cut_off_year+1):max(year(batting$date))) {\n  train &lt;- batting %&gt;%\n    filter(year(date) &lt; i)\n  weights[i] &lt;- get_optimal_weight(\n    warm_up_cut_off_year,\n    year(train$date),\n    train$score,\n    !train$dismissed\n  )\n}\n\nprint(paste0(\"The optimal weight is: \", weights[i]))\n\n[1] \"The optimal weight is: 0.268949564172078\"\n\n\nAnd lets again calculate our predicted parameters for the test set:\n\nparams_by_timestep &lt;- numeric(nrow(batting))\nfor (i in (train_cut_off_year+1):max(year(batting$date))) {\n  params_by_timestep[i] &lt;- get_params_by_timestep(\n    weights[i],\n    warm_up_cut_off = warm_up_cut_off_year,\n    timestep_vec = year(batting$date),\n    score_vec = batting$score,\n    not_out_vec = !batting$dismissed\n  )[i]\n}\n\nweighted_moving_ave_preds_by_year_df &lt;- tibble(\n  year  = 1:max(year(batting$date)),\n  param = params_by_timestep\n) %&gt;%\n  filter(year &gt; train_cut_off_year) \n\nweighted_moving_ave_preds_by_year_df %&gt;%\n  ggplot(aes(x = year, y = param)) +\n  geom_point() +\n  scale_x_continuous(name = \"Year\") +\n  scale_y_continuous(name = \"Parameter\")"
  },
  {
    "objectID": "posts/2021-11-18-a-statistical-analysis-of-jimmy-andersons-test-career-in-r/index.html#state-space-model",
    "href": "posts/2021-11-18-a-statistical-analysis-of-jimmy-andersons-test-career-in-r/index.html#state-space-model",
    "title": "A Statistical Analysis of Jimmy Andersons Test Batting Career in R",
    "section": "State Space Model",
    "text": "State Space Model\nI will now construct a different type of time series model, called a state space model. We will let the parameter of the geometric distribution be the state, and then let this value evolve over time. We will let the state evolve through the equation \\(\\theta_{t+1} \\sim \\mathcal{N(\\theta_{t}, \\sigma)}\\).\nI have written this model in a language called Stan, a probabilistic programming language for statistical inference. I display the model below.\n\nwriteLines(readLines(\"stan_models/model.stan\"))\n\nfunctions {\n  real geometric_lpmf(int y, real theta) {\n    return log(theta) + y * log(1 - theta);\n  }\n  real geometric_lccdf(int y, real theta) {\n    return (y + 1) * log(1 - theta);\n  }\n}\n\ndata {\n  int&lt;lower=1&gt; num_outs;\n  int&lt;lower=1&gt; num_not_outs;\n  int&lt;lower=1&gt; ntimesteps;\n  int&lt;lower=1, upper=ntimesteps&gt; timestep_out[num_outs];\n  int&lt;lower=1, upper=ntimesteps&gt; timestep_not_out[num_not_outs];\n  int&lt;lower=0&gt; score_out[num_outs];\n  int&lt;lower=0&gt; score_not_out[num_not_outs];\n}\n\nparameters {\n  real initial_param;\n  real unscaled_param[ntimesteps-1];\n  real&lt;lower=0&gt; sigma;\n}\n\ntransformed parameters {\n  real param[ntimesteps];\n  real transformed_param[ntimesteps];\n  param[1] = initial_param;\n  for (k in 2:ntimesteps) {\n    param[k] = param[k-1] + unscaled_param[k-1] * sigma;\n  }\n  transformed_param = inv_logit(param);\n}\n\nmodel {\n  for (i in 1:num_outs) {\n    target += geometric_lpmf(score_out[i] | transformed_param[timestep_out[i]]);\n  }\n  for (i in 1:num_not_outs) {\n    target += geometric_lccdf( (score_not_out[i] - 1) | transformed_param[timestep_not_out[i]]);\n  }\n  initial_param ~ normal(-2.25, 0.5);\n  unscaled_param ~ std_normal();\n  sigma ~ std_normal();\n}\n\n\nNow, it can be difficult to fit a state space model with too many parameters, so I will only run this model where each timestep is a year. Below I load in the model and do statistical inference.\n\nmodel &lt;- stan_model(\"stan_models/model.stan\")\n\nhash mismatch so recompiling; make sure Stan code ends with a blank line\n\ntrain &lt;- batting %&gt;%\n  filter(year(date) &lt;= train_cut_off_year)\n\nstandata &lt;- list(\n  num_outs = sum(train$dismissed),\n  num_not_outs = sum(!train$dismissed),\n  ntimesteps = max(year(train$date)) - 2002,\n  timestep_out = year(train$date[train$dismissed]) - 2002,\n  timestep_not_out = year(train$date[!train$dismissed]) - 2002,\n  score_out = train$score[train$dismissed],\n  score_not_out = train$score[!train$dismissed]\n)\n\nfit &lt;- sampling(model, standata, seed = 1, iter = 10000, control = list(adapt_delta = 0.995))\n\nThe first thing to do after MCMC is to check the fit. Let’s start by printing the output of the fit.\n\nprint(fit)\n\nInference for Stan model: anon_model.\n4 chains, each with iter=10000; warmup=5000; thin=1; \npost-warmup draws per chain=5000, total post-warmup draws=20000.\n\n                         mean se_mean   sd    2.5%     25%     50%     75%\ninitial_param           -2.48    0.00 0.26   -3.07   -2.64   -2.46   -2.31\nunscaled_param[1]        0.08    0.01 0.93   -1.75   -0.54    0.08    0.71\nunscaled_param[2]        0.08    0.01 0.94   -1.78   -0.55    0.07    0.70\nunscaled_param[3]        0.10    0.01 0.93   -1.72   -0.52    0.09    0.73\nunscaled_param[4]        0.00    0.01 0.91   -1.79   -0.60    0.00    0.62\nunscaled_param[5]       -0.30    0.01 0.93   -2.06   -0.94   -0.33    0.31\nunscaled_param[6]        0.36    0.01 0.88   -1.37   -0.22    0.36    0.93\nunscaled_param[7]        0.87    0.01 0.92   -1.03    0.29    0.90    1.49\nunscaled_param[8]       -0.06    0.01 0.93   -1.79   -0.70   -0.09    0.56\nunscaled_param[9]        0.25    0.01 0.87   -1.47   -0.31    0.25    0.83\nunscaled_param[10]       0.00    0.01 0.86   -1.66   -0.57   -0.01    0.56\nunscaled_param[11]      -0.28    0.01 0.88   -1.91   -0.88   -0.31    0.29\nunscaled_param[12]       0.50    0.01 0.90   -1.38   -0.08    0.53    1.10\nunscaled_param[13]       0.02    0.01 0.91   -1.77   -0.59    0.01    0.63\nsigma                    0.20    0.00 0.16    0.01    0.08    0.16    0.28\nparam[1]                -2.48    0.00 0.26   -3.07   -2.64   -2.46   -2.31\nparam[2]                -2.46    0.00 0.27   -3.06   -2.61   -2.44   -2.29\nparam[3]                -2.45    0.00 0.29   -3.09   -2.60   -2.42   -2.28\nparam[4]                -2.42    0.00 0.25   -2.97   -2.57   -2.41   -2.27\nparam[5]                -2.43    0.00 0.23   -2.92   -2.55   -2.41   -2.29\nparam[6]                -2.52    0.00 0.23   -3.08   -2.65   -2.49   -2.36\nparam[7]                -2.45    0.00 0.19   -2.87   -2.55   -2.42   -2.32\nparam[8]                -2.23    0.00 0.22   -2.59   -2.38   -2.26   -2.13\nparam[9]                -2.29    0.00 0.19   -2.68   -2.40   -2.29   -2.17\nparam[10]               -2.23    0.00 0.17   -2.55   -2.35   -2.24   -2.13\nparam[11]               -2.24    0.00 0.17   -2.56   -2.35   -2.25   -2.14\nparam[12]               -2.33    0.00 0.19   -2.76   -2.43   -2.31   -2.21\nparam[13]               -2.20    0.00 0.20   -2.56   -2.33   -2.22   -2.08\nparam[14]               -2.20    0.00 0.23   -2.63   -2.35   -2.22   -2.06\ntransformed_param[1]     0.08    0.00 0.02    0.04    0.07    0.08    0.09\ntransformed_param[2]     0.08    0.00 0.02    0.04    0.07    0.08    0.09\ntransformed_param[3]     0.08    0.00 0.02    0.04    0.07    0.08    0.09\ntransformed_param[4]     0.08    0.00 0.02    0.05    0.07    0.08    0.09\ntransformed_param[5]     0.08    0.00 0.02    0.05    0.07    0.08    0.09\ntransformed_param[6]     0.08    0.00 0.02    0.04    0.07    0.08    0.09\ntransformed_param[7]     0.08    0.00 0.01    0.05    0.07    0.08    0.09\ntransformed_param[8]     0.10    0.00 0.02    0.07    0.08    0.09    0.11\ntransformed_param[9]     0.09    0.00 0.02    0.06    0.08    0.09    0.10\ntransformed_param[10]    0.10    0.00 0.02    0.07    0.09    0.10    0.11\ntransformed_param[11]    0.10    0.00 0.02    0.07    0.09    0.10    0.11\ntransformed_param[12]    0.09    0.00 0.01    0.06    0.08    0.09    0.10\ntransformed_param[13]    0.10    0.00 0.02    0.07    0.09    0.10    0.11\ntransformed_param[14]    0.10    0.00 0.02    0.07    0.09    0.10    0.11\nlp__                  -367.95    0.06 3.59 -375.46 -370.24 -367.80 -365.49\n                        97.5% n_eff Rhat\ninitial_param           -2.02 12192    1\nunscaled_param[1]        1.90 21408    1\nunscaled_param[2]        1.94 22661    1\nunscaled_param[3]        1.94 21908    1\nunscaled_param[4]        1.82 23783    1\nunscaled_param[5]        1.57 18775    1\nunscaled_param[6]        2.09 22763    1\nunscaled_param[7]        2.59 15050    1\nunscaled_param[8]        1.85 16593    1\nunscaled_param[9]        1.96 22638    1\nunscaled_param[10]       1.73 23524    1\nunscaled_param[11]       1.55 19090    1\nunscaled_param[12]       2.21 17907    1\nunscaled_param[13]       1.85 24889    1\nsigma                    0.61  5534    1\nparam[1]                -2.02 12192    1\nparam[2]                -1.95 19298    1\nparam[3]                -1.89 19299    1\nparam[4]                -1.93 23715    1\nparam[5]                -2.00 22523    1\nparam[6]                -2.16 10851    1\nparam[7]                -2.13 15148    1\nparam[8]                -1.71 11187    1\nparam[9]                -1.89 21349    1\nparam[10]               -1.86 17812    1\nparam[11]               -1.88 19119    1\nparam[12]               -2.00 18853    1\nparam[13]               -1.76 14021    1\nparam[14]               -1.71 18471    1\ntransformed_param[1]     0.12 12966    1\ntransformed_param[2]     0.12 20119    1\ntransformed_param[3]     0.13 19828    1\ntransformed_param[4]     0.13 23666    1\ntransformed_param[5]     0.12 22634    1\ntransformed_param[6]     0.10 10415    1\ntransformed_param[7]     0.11 14900    1\ntransformed_param[8]     0.15 11247    1\ntransformed_param[9]     0.13 21272    1\ntransformed_param[10]    0.13 17920    1\ntransformed_param[11]    0.13 19189    1\ntransformed_param[12]    0.12 19046    1\ntransformed_param[13]    0.15 14017    1\ntransformed_param[14]    0.15 18314    1\nlp__                  -361.29  4160    1\n\nSamples were drawn using NUTS(diag_e) at Tue May 21 14:11:04 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\n\nSo the Rhat value is 1 for everything, which should mean that the chains are well mixed. We can see that the effective sample size is lowest for the sigma parameter. Let’s take a look at the traceplot for this and a few other parameters, just to check that the model has fit okay.\n\ntraceplot(fit, \"sigma\")\n\n\n\n\n\n\n\n\n\ntraceplot(fit, \"initial_param\")\n\n\n\n\n\n\n\n\n\ntraceplot(fit, \"unscaled_param[1]\")\n\n\n\n\n\n\n\n\nThe traceplot for all these parameters look good and the chains are well mixed. Therefore we can conclude that our chains have probably converged.\nWe now want to calculate our predicted parameters for each year. To do this, we need to retrain the model for each year with the updated dataset (a technique called filtering is often used to do this instead of retraining the model).\n\nfits &lt;- list()\nfor (i in (train_cut_off_year+1):max(year(batting$date))) {\n  train &lt;- batting %&gt;%\n    filter(year(date) &lt; i)\n  standata &lt;- list(\n    num_outs = sum(train$dismissed),\n    num_not_outs = sum(!train$dismissed),\n    ntimesteps = max(year(train$date)) - 2002,\n    timestep_out = year(train$date[train$dismissed]) - 2002,\n    timestep_not_out = year(train$date[!train$dismissed]) - 2002,\n    score_out = train$score[train$dismissed],\n    score_not_out = train$score[!train$dismissed]\n  )\n  fits[[as.character(i)]] &lt;- sampling(\n    model,\n    standata,\n    seed = 1,\n    iter = 10000,\n    control = list(adapt_delta = 0.995),\n    open_progress = FALSE,\n    show_messages = FALSE,\n    refresh = -1\n  )\n}\n\nSince we have refitted the models on each extra bit of training data, we now have our predicted parameters. Lets plot them to see what they look like.\n\nparams_by_timestep &lt;- numeric(nrow(batting))\nfor (i in (train_cut_off_year+1):max(year(batting$date))) {\n  params_by_timestep[i] &lt;- extract(fits[[as.character(i)]])[[\"transformed_param\"]][,i-2003] %&gt;% mean\n}\n\nstate_space_preds_df &lt;- tibble(\n  year  = 1:max(year(batting$date)),\n  param = params_by_timestep\n) %&gt;%\n  filter(year &gt; train_cut_off_year)\n\nstate_space_preds_df %&gt;%\n  ggplot(aes(x = year, y = param)) +\n  geom_point() +\n  scale_x_continuous(name = \"Year\") +\n  scale_y_continuous(name = \"Parameter\")"
  },
  {
    "objectID": "posts/2022-02-11-IPL-2022-Pre-Auction-Indian-Player-Analysis/index.html",
    "href": "posts/2022-02-11-IPL-2022-Pre-Auction-Indian-Player-Analysis/index.html",
    "title": "IPL 2022 Pre Auction Indian Player Analysis",
    "section": "",
    "text": "The auction for IPL 2022 gets underway on the 12th and 13th of February. Its being termed a “mega” auction as most teams need to pick entirely new squads - they all only have a maximum of 4 players at the moment, and the rest need to be picked in this auction. Therefore, there is lots of talk and debate about which franchises will want which players. With the quantity of players available at auction (590 in total, 370 from India and 220 overseas), some data analysis is useful to diagnose which players are valuable where other franchises might not think so.\nIn this analysis, I will look at the Indian players that are available. Starting with the homegrown players allows us to see what types of player Indian cricket is stronger/weaker in, and therefore you can choose your overseas players to compensate for these weaknesses.\nEach player in the auction list is given a specialism (batsman, wicketkeeper, all-rounder or bowler), and I will go through the different specialisms one by one and analyse the relevant data for the players with this specialism. All analysis shall be done on post pandemic major T20 competitions data - this means that for the majority of the Indian players available, the only data that I have is the past two years of IPL data. We therefore have to be mindful of some small sample sizes in the results.\nFirst, let’s take a look at the batters. Only looking at players who have faced at least 100 balls in the dataset, I plot their balls per dismissal against their strike rate. I also add the league average during this time for top 6 batters.\n\n\n\n\n\n\n\n\n\nSo from this graphic, we can see that Shikhar Dhawan is the best available anchor batsman, with a strike rate similar to the league average but a much better balls per dismissal rate. Other useful anchor batter appear to be Manish Pandey, Shreyas Iyer, Devdutt Padikkal and Saurabh Tiwary, who all have a balls per dismissal rate of at least 25 and a strike rate of at least 120. The only player in this category with a strike rate much higher than the league average is Rahul Tripathi - given that he is the only player in this category this could make him pretty valuable.\nLet’s move on to the wicketkeepers now. They can be compared with the batters from above, but have the added value of keeping wicket. I won’t do any analysis on their actual keeping ability, as this is difficult to get accurate results without detailed data. So for now, let’s just look at their batting ability, and this can be compared with the players above. I will again add the league average for top 6 batters.\n\n\n\n\n\n\n\n\n\nIshan Kishan has been talked about as being the most expensive buy of the mega auction, and from his stats it’s not difficult to see why; these are better than anyone else’s including the specialist batters. Ambati Rayudu also has excellent statistics over the past two years, and expect to see a lot of franchises want him in their middle order despite his age. Whilst he has rarely kept wicket, the fact that he can makes him a useful addition to any squad because he can take the gloves if the first choice keeper is ever unavailable. KS Bharat will also be wanted by teams despite a lower strike rate than the previous two. A final note to add: Dinesh Karthik’s stats are a touch misleading - he usually comes into an innings late, and so has to attack immediately without having time to play himself in. A statistical model would allow you to control for this and compare his ability to others’ better.\nThe next category is Indian all-rounders. I’ve taken a look at the players list, and in my opinion they can all be categorised as either a stronger batter or a stronger bowler. We shall therefore compare the two categories separately. First let’s look at those who are stronger batters. We will look at both their batting and bowling abilities this time - we will compare their batting strike rate with their balls per dismissal to assess their batting ability like before, but we will also look at their bowling economy rate, bowling balls per dismissal and the average number of balls they bowl per game.\n\n\n\n\n\n\n\n\n\n\nBowling Statistics for Batting All-Rounders\n\n\n\n\n\n\n\n\n\n\nName\nMatches\nBalls Bowled\nAvg Balls Per Match\nEconomy Rate\nBalls Per Dismissal\n\n\n\n\nN Rana\n32\n24\n0.8\n8.8\nInf\n\n\nDJ Hooda\n17\n102\n6.0\n8.5\n51.0\n\n\nM Shahrukh Khan\n10\nNA\nNA\nNA\nNA\n\n\nR Parag\n18\n49\n2.7\n12.2\n49.0\n\n\nAbhishek Sharma\n16\n120\n7.5\n7.8\n20.0\n\n\nS Dube\n19\n84\n4.4\n8.7\n21.0\n\n\nV Shankar\n13\n145\n11.2\n7.5\n20.7\n\n\nMK Lomror\n7\n42\n6.0\n6.7\n42.0\n\n\nKM Jadhav\n10\nNA\nNA\nNA\nNA\n\n\n\n\n\nIf we look at the table of bowling statistics, we can see that a lot of these all-rounders are not… all-rounders. We don’t have any bowling data for Shahrukh Khan or Kedhar Jadhav, and not much for Nitish Rana or Riyan Parag either. These players should be evaluated on their batting alone.\nDeepak Hooda and Shahrukh Khan both represent good aggressive Indian batters, and Hooda averages one over a game with his off spin too. Abhishek Sharma has a high-ish strike rate and bowls a lot too, which makes him valuable. Rana is an average batsman judging from the data - whilst this doesn’t make him sound great he will be sought after because there’s a lot that are worse than him. Shivam Dube and Mahipal Lomror are both okay if they can come cheap and play as your 6th batter/6th bowler.\nLets now look at the all-rounders that I have classified as being stronger bowlers. To begin with, lets just look at their batting statistics.\n\n\n\nBatting Statistics for Bowling All-Rounders\n\n\n\n\n\n\n\n\n\n\nName\nMatches\nInns\nBalls Faced\nStrike Rate\nBalls Per Dismissal\n\n\n\n\nR Ashwin\n33\n11\n76\n106.6\n15.2\n\n\nKH Pandya\n30\n25\n218\n117.0\n14.5\n\n\nHV Patel\n22\n11\n81\n121.0\n11.6\n\n\nWashington Sundar\n29\n17\n158\n103.2\n12.1\n\n\nShahbaz Ahmed\n10\n8\n54\n111.1\n7.7\n\n\nHarpreet Brar\n8\n5\n58\n110.3\nInf\n\n\nShivam Mavi\n17\n5\n34\n102.9\n8.5\n\n\nKL Nagarkoti\n11\n7\n33\n66.7\n8.2\n\n\nR Tewatia\n28\n22\n330\n124.2\n20.6\n\n\nJ Yadav\n7\n3\n26\n130.8\n13.0\n\n\n\n\n\nMany of these players have nothing to suggest that their batting could be useful. Rahul Tewatia has the best batting stats, Krunal Pandya’s stats suggest that he could be useful, and Harshal Patel can hit a few boundaries later on in the innings. Jayant Yadav has a good strike rate but from a very small sample size and Harpreet Brar has never been out in his 58 balls faced. As for the rest - in my opinion their batting abilties’ shouldn’t be taken into account and they should be judged on their bowling alone. Some of them like Ravi Ashwin may be able to stick around, but if they are coming in at 8 or lower then this is of very little use to the team.\nI will look at their bowling abilities’ now, and I will combine this with the specialist bowlers. I will do the analysis for pace and spin bowlers separately. Lets look at spinners first. We again include a league average for spinners over this period.\n\n\n\n\n\n\n\n\n\nFrom this graph I can see Harpreet Brar and Washington Sundar as two good defensive spinners. I can also see two good aggressive spinners in Yuzvendra Chahal and Amit Mishra. Rahul Chahar and Murugan Ashwin are not too far from these two, whilst the more well known Ashwin is a good pick for an all round spinner in terms of wicket taking and economy rate. Rahul Tewatia, Krunal Pandya and Jayant Yadav are also valuable players given their batting abilities, but you wouldn’t like them to be the team’s main spinner. That’s ten Indian spinners that I have listed as good picks - along with the four Indian spinners that already have a team for the 2022 IPL this shows the strength in depth that India have in this department, and therefore an overseas spinner has to be elite in order to pick up a contract.\nThe final section of players that we will take a look at are pace bowlers. Upon exploring the data, I think it is best to look at and compare them in two main phases of the game that they operate: the powerplay and the death. Be mindful that the axis are different on both of these graphs below. I will include league averages for pace bowlers in both phases of the game as benchmarks.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLooking at the graph for the powerplay data, the only two players with better than average values for both economy rate and balls per dismissal are Avesh Khan and Shivam Mavi. Bhuvneshwar Kumar leads the way in terms of economy rate and is the only player to go at better than a run a ball in this period, with Sandeep Sharma, T Natarajan and Mohammed Shami all going at better than 7s. Whilst Shardul Thakur goes at 9 runs per over in this phase of the game, he does have the best balls per dismissal rate.\nAs for the death overs, the most important metric here is economy rate because wickets are not as important compared to earlier in the game. Deepak Chahar leads the way with a very impressive economy rate of less than 8, about 2 runs better than the league average. This is actually not what I expected - Deepak Chahar is renowned to be a bit of a powerplay specialist with the ball, yet over the past two years the data shows that he has been better at the death. Avesh Khan is the only player with an economy rate of less than 9, whilst Harshal Patel and T Natarajan are both better than the league average in both of the measures.\nThat completes the final category of Indian players to look at in the auction pool. Judging by the analysis above, there are a few valuable picks for each category. Whilst these are very basic statistics and so need to be taken with a pinch of salt, it is an easy starting point and appears to be a good one since a lot of the graphs and results align with our prior knowledge of the players.\nIn summary, my list of data driven picks from the Indian contingent are as follows:\n\nAnchor batters: Shikhar Dhawan\nAggressive batters: Ishan Kishan, Ambati Rayudu, Rahul Tripathi, Deepak Hooda, Shahrukh Khan\nBatting all-rounders: Abhishek Sharma\nSpin bowling all-rounders: Krunal Pandya, Rahul Tewatia, Jayant Yadav\nAggressive spin bowlers: Yuzrendra Chahal, Amit Mishra\nDefensive spin bowlers: Harpreet Brar, Washington Sundar\nPowerplay pace bowlers: Avesh Khan, Shivam Mavi, Bhuvneshwar Kumar\nDeath pace bowlers: Avesh Khan, Deepak Chahar, Harshal Patel, T Natarajan"
  },
  {
    "objectID": "posts/2021-08-03-a-shiny-dashboard-for-cricket-scoring/index.html",
    "href": "posts/2021-08-03-a-shiny-dashboard-for-cricket-scoring/index.html",
    "title": "A Shiny Dashboard for Cricket Scoring",
    "section": "",
    "text": "As I said in my previous blog post, I am a cricket fanatic. I’ve always wanted to find a resource where I could see the scorecard of professional cricket matches - as an example see the scorecard here. However there did not appear to be anywhere that did this, so I decided to create a web application myself to do this. As a strong R programmer, Shiny seemed like a great tool that would allow me to do this. The app can be found here."
  },
  {
    "objectID": "posts/2021-08-03-a-shiny-dashboard-for-cricket-scoring/index.html#how-to-use",
    "href": "posts/2021-08-03-a-shiny-dashboard-for-cricket-scoring/index.html#how-to-use",
    "title": "A Shiny Dashboard for Cricket Scoring",
    "section": "How to use",
    "text": "How to use\nThe Matches tab gives you a list of Twenty20 matches for the specified date range, competitions and even a certain team if you decide to. For the match that you would like to view, then click on the “Go to Scorecard” button and the scorecard will open in the Scorecard tab. You can also toggle which innings you would like to see. To change the match, go back to the Matches tab and click on a new game.\nPlease be aware that if you have not yet selected a match by clicking the “Go to Scorecard” button in the Matches tab, then the Scorecard tab will be full of errors."
  },
  {
    "objectID": "posts/2021-08-03-a-shiny-dashboard-for-cricket-scoring/index.html#future-to-dos",
    "href": "posts/2021-08-03-a-shiny-dashboard-for-cricket-scoring/index.html#future-to-dos",
    "title": "A Shiny Dashboard for Cricket Scoring",
    "section": "Future to dos",
    "text": "Future to dos\n\nMore formats other than just Twenty20.\nUse different colours for different bowlers, so you can see how each batsman fared against the different bowlers.\nAdd the ability to click on a player and see an analytical overview of their stats broken down by year, competiton, etc."
  },
  {
    "objectID": "posts/2021-12-31-structuring-the-english-county-season/index.html",
    "href": "posts/2021-12-31-structuring-the-english-county-season/index.html",
    "title": "Structuring the English County Season",
    "section": "",
    "text": "After England quite emphatically lost the third test and therefore the series to Australia a few days ago, there has been a lot of discussion on what is to blame. One thing that has been brought up a lot and probably the most is the English county season. The introduction of the Hundred competition and pushing the county championship to the fringes of the season have been frequently mentioned. In this post, I will layout how I would structure the season if I was the ECB.\nFirstly, before coming up with a structure, I think it’s important to think what purpose the county game serves. In my opinion, it is for the following reasons: * Make future English cricketers * Give current supporters what they want, which is being able to see their team playing high quality competitive cricket * Engage new fans * Be financially viable\nWith this in mind, I think the following structure works perfectly to serve these reasons:\nCompetitions * County Championship. Two divisions,with division one having 10 teams and division two having 8. Two teams get promoted/relegated each season. 13 games are played in divison one, with each team playing each other once before the table splits and the top 5 all playing one more game against each other, and similarly with the bottom 5 (SPL football style). 14 games are played in division two with each team playing each other home and away. * One Day Trophy. North and south groups with 9 teams in each, with 8 games being played, 4 at home and 4 away. A knock out stage follows to decide the winner. The group games are played on Sundays to help increase attendances during the first half of the summer. * T20 Blast. The whole competition is played in a 3.5 week block, with 8 games and a north/south group split like before, followed by quarter finals and then a finals day. Home and away games are the inverse of what happened in the one day trophy. No international white ball matches for England are scheduled during this so that the best players are available.\nSchedule\n\nMid April - Mid July: 9 county championship games and the entire one day trophy competition.\nMid July - Mid Aug: T20 Blast competiton.\nMid Aug - Late Sept: Final 5 rounds of the county championship (in divison 1 each team will only play 4 games and not play for one of the rounds)\n\nJustifications * There is not enough time in the calendar to play four competitions, as proven with the neglect of the one day trophy in 2021. The T20 Blast and the Hundred are very similar, and therefore you only require one. The T20 Blast sells out at all stadiums, and you can allow even more people to watch games by having more teams. The supporters of all teams deserve to see T20 games, not just those who luckily live in cities where test matches are played. The aspects that engaged new fans with the Hundred were the marketing and the TV air time, which could be replicated regardless of the teams in the competition. If the ECB really feel the need for a new format then the Blast can be a hundred balls per team competition. The only downside of losing the Hundred is that the quality of the competition then thins due to more teams competing, so this will probably weaken the English white ball teams. But the quantity of overseas T20 competitions means that there are many opportunities to play high quality white ball cricket before the international stage. * The county championship is not banished (as much) to the sides of the season, so there are better conditions which will hopefully help towards producing international quality test cricketers. The final five rounds of the county championship are played without any other competitions happening, in order to allow the players to play their best quality cricket. Due to the format, the cricket should also be competitive at this stage with most teams fighting for something. Happening after the Blast can also help engage some of the newly aquired cricket fans into following the end of the county championship season. * The one day trophy is played on Sundays in order to get more fans in. This means that this isn’t played in a block, however this is too difficult to achieve without downgrading the county championship or the one day trophy itself. The requirement to be played in a single block is not as great as the Blast because there is not the same quantity of overseas players. Furthermore, some players like a bit of variety, and having the one day trophy at the same time as the county championship can give themselves a chance to play more freely. Players still get a chance to play white ball cricket in a block with the Blast later in the summer."
  },
  {
    "objectID": "posts/2023-05-17-introducing-contribution-score/index.html",
    "href": "posts/2023-05-17-introducing-contribution-score/index.html",
    "title": "Introducing Contribution Score",
    "section": "",
    "text": "In cricket, the traditional metric to quantify how good a player is their batting average for their batting ability, and bowling average for their bowling ability. Whilst there are limitations of using this metric in test cricket (for example, if a batter has mostly played against weak bowling attacks or on flat pitches then they will have a higher batting average but not necessarily be better), the match situation does not really dictate the style that a player will play - the majority of the time they want to score as many runs as possible if they are a batter, or take as many wickets for as few runs as possible if they are a bowler. In limited overs cricket, the goal is not neccessarily the same. For example, if you enter the innings as a batter with 8 wickets left and 5 overs remaining, then a score of 5(3) will almost certainly be better for your team than scoring 10(10). This is because in the first scenario your team is likely to score more runs than in the second scenario despite you personally scoring less runs. The goal as a batter is to maximise the number of runs that your team scores, not the number of runs that you score. For bowlers, it is simply the inverse.\nThis problem has been realised, and therefore there is a lot of talk about strike rate these days (economy rate for bowlers). This is simply the runs per ball that you score/concede. However, this metric alone is not enough because strike rate is often compensated by a lower average (since you are being more aggressive and therefore not batting at your optimal way) and a high average is still valuable - the cost of losing a wicket varies upon the situation but in some it can be very costly. So the amount you are willing to compensate depends upon the game situation. Also different players have different strengths - some are able to bat at a high average but struggle to maintain a high strike rate (such as Virat Kohli), whereas others bat at a high strike rate but struggle to maintain a high average (such as Tim David).\nIdeally we would like a metric that could look at the game situation, and tell you how a player has performed based upon that. Well I present to you contribution score. I define the contribution score as follows:\n\nThe contribution score for a batter is the difference in the number of runs that a team scores compared with the expected score if that batter was replaced with an average batter for his position in the competition, given the opposition bowlers and the ground conditions. For a bowler, this is again the difference in the number of runs that a team scores compared with the expected score but this time if the bowler was replaced with an average bowler for the competition, given the opposition batters and the ground conditions.\n\nThe neat thing about this is that if we take the contribution scores for all batters, sum them up and then subtract this value from the innings score then we have what the expected score is for an average team in this competition against this bowling attack at this venue. Lets do an example to make things clearer.\nTake the first innings of England v Pakistan at Headingley in 2021, the scorecard can be found here. England scored 200 in this innings. Pakistan are a strong bowling team, and you would expect an average international team to score 164 against them at Headingley. England therefore scored 36 more runs than expected, and for each batter we can see how much they contributed to this total in the graph below:\n\n\n\nbatters contributions plot\n\n\nJos Buttler’s innings was the largest contribution, adding 21.6 runs more than the expected score, with Moeen Ali and Liam Livingstone also providing significant contributions. Dawid Malan’s contribution had the most negative impact - a combination of being out in the third over of the innings and only scoring 1 run from the 5 deliveries he faced.\nWhat about the bowler’s contributions? Since England are a strong batting team, we would expect an average international team to concede 181 runs against them at Headingley. Pakistan therefore conceded 19 more runs less than expected, and for each bowler we can see how much they contributed in the graph below:\n\n\n\nbowlers contributions plot\n\n\nThis graph tells us that the only bowler to perform better than an average bowler was Imad Wasim. Interestingly, Mohammad Hasnain performed better than Shaheen Shah Afridi despite an economy rate of 12.75 compared with an economy rate of 7.30 - this can mostly be credited to Hasnain claiming the wickets of Buttler and Moeen at important times of the innings. We can also see the contribution from Liam Livingstone being run out - it decreased the expected total by 7.5 runs.\nThe only metric that I have found similar to this is the Cricviz Match Impact metric. Whilst this does assign a plus or minus score to every ball in the match according to whether the expected total has increased or decreased, which is the same as my contribution score metric does, I’m unsure what their definition of expected is - I have clearly defined mine which is for an average team in the competition at the venue given the opposition, and therefore you have two different expected scores; one for an average batting team against the given bowling line up and another for an average bowling team against the given batting line up.\nBefore jumping to conclusions and saying that this metric has solved the problem of evaluating performance in Twenty20 cricket, it is important to first understand its limitations. The primary one being that since this is based upon the expected score, which comes from a statistical model using the data available at cricsheet.org, it has no true value. One model could give a different value for expected score to another, which would then give different contribution scores. This is unlike metrics such as batting average and strike rate, which are fixed and not subjective. Another thing worth noting is that the definition of contribution score doesn’t fit as well for the second innings since a team cannot score more than the target set.\nContribution scores can go a long way to helping us get a better understanding of how to win a match of Twenty20 cricket. In particular, this can be instrumental in squad selection. Suppose you have the first pick of a draft with every player in the world available. Who do you choose? Do you choose Jos Buttler, the world’s best opening batter; Suryakumar Yadav, the best middle order batter; Rashid Khan, the best spin bowler; or Jasprit Bumrah, the best pace bowler? Your answer should put a lot of weight lot upon how much better these are than their alternatives - contribution score allows you to put a single number upon these so you are able to come to a conclusion."
  },
  {
    "objectID": "posts/2023-06-26-IPL-final-contributions-scorecard/index.html",
    "href": "posts/2023-06-26-IPL-final-contributions-scorecard/index.html",
    "title": "IPL Final Contributions Scorecard",
    "section": "",
    "text": "Following on from my previous post, let’s see some more contribution scores! The IPL season concluded a few weeks ago, and it was arguably the best yet, with the final being incredibly entertaining.\nIt was fitting for the highest scoring season in the tournament’s history that the final was a runs fest. This has really tested my contribution score metric - the expected runs totals that this metric relies on is based upon a model that is fitted to the last five years of data all of which is equally weighted. Since this was a record scoring season, the contribution scores are therefore generally positive because most scores are greater than what my model expects.\nGujarat batted first and scored 214/4. Let’s take a look at the contribution score graphic.\n\n\n\nbatters contribution first innings plot\n\n\nBased upon the bowling attack that Chennai Super Kings chose, an average IPL team would be expected to score 169 at the Narendra Modi stadium. Gujarat scored quite a few more than that primarily due to Sai Sudharsan, with the openers also contributing. We can see an excellent example of the benefits of contribution score compared to traditional metrics in the comparison of the opening partnership - Shubman Gill has a higher contribution score than Wriddhiman Saha despite scoring 15 less runs.\nLet’s take a look at the contributions of the bowlers.\n\n\n\nbatters contribution second innings plot\n\n\nGujarat’s expected score against an average IPL bowling attack at this stadium was 176. It makes sense that this is larger than the previous expected score, since both of these teams should be better than average since this was the final. None of the bowlers recorded a contribution score of below zero (signifying an above average performance), but this was a very high scoring match.\nThere was a delay because of rain during the match interval, but when Chennai came out to bat they were set a DLS adjusted target of 171 runs in 15 overs. In a thrilling chase, Chennai ended up requiring 10 from the final two balls, with Ravi Jadeja being the hero and pulling off a remarkable chase. Let’s take a look at the contribution scores of the batters for this innings.\n\n\n\nbatters contribution second innings plot\n\n\nThe expected score here (132) is what an average batting team is expected to score against Gujarat’s bowling attack in a reduced 15 overs innings. One of the key factors behind the success of CSK’s chase was that every batter was very positive and it was a team affair to get them over the line - this is reflected in the contribution scores with six of the seven batters recording a positive contribution score; only MS Dhoni who got a first baller didn’t.\nLet’s now take a look at the contribution scores of the Gujurat bowlers.\n\n\n\nbowlers contribution second innings plot\n\n\nThe depth of Chennai’s batting and the strength of Gujarat’s bowling is reflected in the expected score of 141 for this innings - nine runs higher than for the previous graphic, and let’s remember that this is only a 15 over innings too. Noor Ahmad was the standout for Gujarat’s bowlers and a contribution score of -15.5 reflects this. Not only is this a remarkable score, he was also the only bowler to record a contribution score of less than 0, adding to how unlucky he was to be on the losing side. Rashid Khan had a rare off day and a game to forget.\nIf you’ve got any other matches that you would like to see these contribution score graphs for then please let me know!"
  },
  {
    "objectID": "posts/2022-05-16-effective-ways-of-working-in-a-remote-data-science-team/index.html",
    "href": "posts/2022-05-16-effective-ways-of-working-in-a-remote-data-science-team/index.html",
    "title": "Effective Ways of Working in a Remote Data Science Team",
    "section": "",
    "text": "The last two years have seen a lot of us work from home, and a lot of us look like we will continue to do so. Working effectively has been something that we have all had issues with, whether this be through not having the right equipment, various distractions around the house or not having the right processes in place in your team. Concerning this last point, tech teams have probably dealt with this better than most. Of course, that is no surprise - people in tech are obviously better with technology than the average person, and it is also an industry that had seen remote working as common place before the pandemic. Nevertheless, this has mostly been amongst software developers, and less so amongst data scientists. A lot of this has been down to not having the correct processes, workflows and communication tools in place. In this article, I will share my thoughts on how a data science team can work remotely effectively. A lot of these tips can in fact be used for a lot of other remote roles too, both technical and non-technical.\nI will split this post into five main sections: communication (how to use various communication tools to maximise productivity), workflow (how individuals carry out their work when working on projects with others), team processes (things that happen repeatedly to ensure the smooth running of the team) review processes (deciding whether a task is complete) and knowledge sharing (how to ensure knowledge is still shared in a remote environment)."
  },
  {
    "objectID": "posts/2022-05-16-effective-ways-of-working-in-a-remote-data-science-team/index.html#communication",
    "href": "posts/2022-05-16-effective-ways-of-working-in-a-remote-data-science-team/index.html#communication",
    "title": "Effective Ways of Working in a Remote Data Science Team",
    "section": "Communication",
    "text": "Communication\nI will talk about three really useful tools that all have slightly different roles, but a lot of people don’t see this. These tools are email, Slack and Zoom. Slack can be replaced by any other instant messaging tool that has both individual and group message capabilities and Zoom can be replaced by any other video calling service, although as you’ll see if you read on I don’t think they should be the same service.\nI think it is best to think about these tools as if you were physically in the office. If you would be in a meeting, then you should obviously be using Zoom. However, if you were to just go up to someone and ask them a question, then Zoom should also be used in my opinion. This is because you can get an instant response, like if you were tapping them on the shoulder in the office. If the response can wait for a couple of hours, then that is where you use Slack to avoid distraction.\nWhat about the differences between email and Slack. In my opinion, the golden question to ask yourself is: do you want there to be an audit trail? If the answer is yes, then you should use email. Email is for messages that are to the point without discussion that can be found again easily. Slack is for quick questions/brief discussions about a project, company announcements or just keeping morale up - all things that don’t need to be retrieved in the future. A piece of advice that I would add is that email and Slack messages shouldn’t expect an instant reply - they can be very distracting and cause you to lose flow, and so I recommend instead just checking them periodically.\nFinally, I would like to add some tips about using Slack in particular. Firstly, keep the number of channels minimal. People can easily end up creating too many channels and it can be difficult to keep track of the announcements in the channels that actually matter. Therefore delete channels once they become no longer irrelevant, for example a channel for a certain project that is finished. Another handy trick which helps with finding channels is to use prefixes - such as “team-” for specific teams, “project-” for projects and “social-” for various water cooler topics - this is suggested on Slack’s website. [1]"
  },
  {
    "objectID": "posts/2022-05-16-effective-ways-of-working-in-a-remote-data-science-team/index.html#workflow",
    "href": "posts/2022-05-16-effective-ways-of-working-in-a-remote-data-science-team/index.html#workflow",
    "title": "Effective Ways of Working in a Remote Data Science Team",
    "section": "Workflow",
    "text": "Workflow\nI am a big advocate of working in an agile way, and whilst a lot of this is usually focussed on processes (which I will describe below), I think it is a great tool when applied to workflow as well. My biggest piece of advice is to work on one thing at a time, and there are many tools that can help with this. Using cards on a kanban board is something that I cannot stress highly enough. This is very prominent in software development, however I think other roles can use this effectively as well. The main critical response in using this is that it is a lot more difficult to plan the direction of the work compared to software development. Whilst this is true, planning is still vital and you should consider what direction the project could go and use kanban boards accordingly. On a card you should clearly describe why you are doing this piece of work, what you are doing and when you know that it is finished.\nI’m sure most people do work on one task at a time, but I’ve seen plenty of people who don’t, and if you are logically minded then I don’t understand why not: you have a clear goal in your head of what you are trying to achieve for this task, it allows you to communicate clearly with others what you are working on, and I’ve found that I am a lot less likely to procrastinate when I know precisely what I am doing.\nAnother great thing about working in this manner is time tracking. If you are working on one thing, then you can clearly see how long you have spent working on different tasks. This is really useful information, because you can then estimate how long future tasks will take based upon how long similar tasks took before, which is one of the most difficult things when it comes to planning."
  },
  {
    "objectID": "posts/2022-05-16-effective-ways-of-working-in-a-remote-data-science-team/index.html#team-processes",
    "href": "posts/2022-05-16-effective-ways-of-working-in-a-remote-data-science-team/index.html#team-processes",
    "title": "Effective Ways of Working in a Remote Data Science Team",
    "section": "Team Processes",
    "text": "Team Processes\nThe main team process that I would like to dicuss is daily stand ups, and how I think you can get the most value from them. I think they are vital for a team for several reasons. Firstly, because of the job that they are there to perform - before you end up working on a piece of work there is one last chance for others in the team to intervene in case they have something useful to help you or the work may no longer be necessary, and you can give the same input to others. They also allow the whole team to see what everyone is working on, keeping people in the loop and allowing everyone to see how a project is materialising. Aside from the main role stand ups perform, they give everyone a little bit of social contact first thing in the day, which I think is good for people’s wellbeing when working remotely and therefore often alone.\nThe name stand up arises because everyone in the team would all usually stand up from behind their desks and have this meeting, perhaps getting up and going to a different room. This is no longer the case when working remotely (although you can of course stand up if you want to), and actually I think being behind your computer can be even more useful because it allows you to look over the kanban board whilst doing the stand up. In particular, I recommend having the following columns on the board: Backlog (tasks that haven’t been started yet), Blocked (tasks that you would like to start but can’t because they are blocked by some other piece of work), Doing (tasks that are currently in process), To Verify (tasks that require somebody to review them), In Review (tasks that have been reviewed and completed), Done (tasks that are done like In Review but they have been completed for more than day). Cards then move across the board from left to right, but during stand up you review these from right to left (ignoring the “Done” column, and only specific cards in the “Backlog” column that people speak up about), with the relevant people making comments upon the status of the cards.\nFinally, I will very briefly mention a couple of other processes that are definitely worth their time, but I don’t have enough expertise to give my opinion on the best way to carry them out. They are planning meetings, to decide what is going to be worked on in the near future, and retrospectives, to say what did and didn’t go well recently in order to learn from and improve in the future."
  },
  {
    "objectID": "posts/2022-05-16-effective-ways-of-working-in-a-remote-data-science-team/index.html#review-processes",
    "href": "posts/2022-05-16-effective-ways-of-working-in-a-remote-data-science-team/index.html#review-processes",
    "title": "Effective Ways of Working in a Remote Data Science Team",
    "section": "Review Processes",
    "text": "Review Processes\nThere are loads of tools that explain what a good review process looks like. The trouble I have is that there are so many, often with so many points that the review process takes longer than the actual work itself! Also, a lot of these focus on the code itself, which is of course important but I will just leave that as one main point really under “coding standards”, which is up to the team to define.\nThe easiest way to do a review is through a checklist and ensure that the following has been done: * The work does what the ticket says * Coding standards are followed * The code is tested (where required) * Documentation has been updated\nDocumentation is one of the most interesting points, this varies across different organisations, from zero documentation to more documentation that code itself! In my opinion, good documentation is multi layered. The first layer is the readme file in a repository. This should contain information of what the repository does, how to run the code in the depository and how to add new code to the repository. Ensuring that the readme is up to date is one of the most important parts of a pull request. The next layer is some kind of team wiki, such as confluence. Trying to have good team documentation is difficult, because it can become very complex as time progresses. I would suggest trying to look at it from the top down, in terms of thinking about what the team does, and then think how the current piece of work fits in to that, so that the documentation is kept up to date in a logical, tree like manner. Sketching this all out by hand multiple times is something that I have found helps in creating this."
  },
  {
    "objectID": "posts/2022-05-16-effective-ways-of-working-in-a-remote-data-science-team/index.html#knowledge-sharing",
    "href": "posts/2022-05-16-effective-ways-of-working-in-a-remote-data-science-team/index.html#knowledge-sharing",
    "title": "Effective Ways of Working in a Remote Data Science Team",
    "section": "Knowledge Sharing",
    "text": "Knowledge Sharing\nThis is something that can be neglected when it comes to remote work (along with things like the social aspect of work), and its important that it isn’t. You miss out on eavesdropping on background chat from the people that sit near you, which between two data scientists is probably something related to data science, as well as just the general chatter about what people are working on. My advice with this is similar to when it comes to most things that remote working entails - try and mimic as if you were in the office together as closely as possible.\nTrying to mimic a spontaneous conversation is obviously a difficult task. And as with all conversations on Zoom, there will be awkwardness at first. But, if you are a podcast listener, then you can see that an online chat doesn’t have to be awkward. There are two things that contribute to this in my view: firstly having a topic to talk about, and secondly engaging in these conversations frequently. Frequent demos satisfy this - each person in the team demonstrates something related to their work that could be of interest to the rest of the team. In a team of about six, I would suggest having these occur every two weeks, so each person gets an opportunity to present once a quarter. This can be of a wide variety, from an algorithm that someone wants to talk about, a particular library, or even something such as a new productivity tool that could be useful for the team. The presentation doesn’t have to be long at all, but it can then lead to a discussion amongst everyone.\nTo support this I would suggest using a slack channel where people can share any interesting new concepts that they come across, possible conferences to attend or to simply ask questions and promote discussion."
  },
  {
    "objectID": "posts/2022-05-16-effective-ways-of-working-in-a-remote-data-science-team/index.html#final-words",
    "href": "posts/2022-05-16-effective-ways-of-working-in-a-remote-data-science-team/index.html#final-words",
    "title": "Effective Ways of Working in a Remote Data Science Team",
    "section": "Final Words",
    "text": "Final Words\nThat was quite a long article, but if you’ve made it this far then congrats and I hope at least some of the sections may provide some use for you and your team. The ideas that I have suggested in this post have been influenced both directly through situations I’ve been in at work and indirectly through research that I have done over the years. This research has mostly consisted of blog reading, and therefore I can’t take full credit for all of these ideas and I appreciate all the great posts that have influenced this.\n[1] - https://slack.com/intl/en-gb/resources/using-slack/how-to-organize-your-slack-channels"
  }
]